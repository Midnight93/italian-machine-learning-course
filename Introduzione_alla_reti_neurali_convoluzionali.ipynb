{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduzione alla reti neurali convoluzionali",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galeone/italian-machine-learning-course/blob/master/Introduzione_alla_reti_neurali_convoluzionali.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAmQWO0FFG8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x \n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM9oF9MPFWMO",
        "colab_type": "text"
      },
      "source": [
        "## Premessa\n",
        "\n",
        "Utilizzeremo lo stesso training loop e struttura del codice definita nel notebook precedente (https://bit.ly/2lno7O5), ma metteremo a confronto le performance della rete di classificazione implementata mediante layer completamente connnessi e quella implementata con layer convoluzionali.\n",
        "\n",
        "## Fully Connected cv CNN per la classificazione di immagini\n",
        "\n",
        "Riprendiamo la struttura della pipeline di ML definita nel precedente notebook:\n",
        "\n",
        "- Ottenere ed Analizzare i dati\n",
        "- Definire la pipeline di input\n",
        "- Definire il modello\n",
        "- Definire le metriche\n",
        "- Definire il training loop\n",
        "- Allenare il modello e misurare le metriche durante ed alla fine di ogni epoca\n",
        "- Selezionare il modello migliore (basandosi sulla metrica di validation)\n",
        "- Misurare le performance sullo split di test\n",
        "\n",
        "Abbiamo già implementato tutti i punti qui descritti, ma basandoci sull'idea che il modello da definire ed utilizzare fosse fully connected.\n",
        "\n",
        "Per cui abbiamo:\n",
        "\n",
        "- definito la pipeline di input per produrre immagini \"flat\" (`32*32*3`)\n",
        "- definito il modello di classificazione usando solo layer FC\n",
        "\n",
        "Per poter utilizzare un modello basato su layer CNN, dobbiamo modificare:\n",
        "\n",
        "- la pipeline: per produrre immagini, quindi tensori `(32,32,3)`\n",
        "- il modello: deve essere in grado di accettare immagini grandi almeno `(32,32,3)`\n",
        "\n",
        "Riprendiamo **tutto** il codice definito nel precedente notebook, e lo utilizziamo come base di partenza per **mettere a confronto** le due soluzioni (FC vs CNN).\n",
        "\n",
        "## La pipeline di input\n",
        "\n",
        "Utilizziamo nuovamente il dataset Cifar10, quindi installiamo TensorFlow Datasets e riutilizziamo il codice già scritto.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ2HK6xTFUlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow_datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QltA2hRfmfXF",
        "colab_type": "text"
      },
      "source": [
        "Ora, senza dilungarci oltre, otteniamo il dataset e definitiamo la funzione `transform` da mappare agli elementi del dataset, in modo tale da creare **l'input per il modello fc**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIVjKsnHox7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wA4TQfgmsbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data, info = tfds.load(\"cifar10\", with_info=True, split=tfds.Split.ALL)\n",
        "def transform(row):\n",
        "  # trasformare i dati da uint a float\n",
        "  row[\"image\"] = tf.image.convert_image_dtype(row[\"image\"], dtype=tf.float32)\n",
        "  # 1-hot\n",
        "  row[\"label\"] = tf.one_hot(row[\"label\"], depth=10, on_value=1, off_value=0)\n",
        "  # [-1,1] range\n",
        "  row[\"image\"] = (row[\"image\"] - 0.5) * 2.\n",
        "  # flatten\n",
        "  row[\"image\"] = tf.reshape(row[\"image\"], (-1,))\n",
        "  return row\n",
        "\n",
        "# Input for the fully connected model\n",
        "dataset_fc = data.map(transform)\n",
        "\n",
        "# split, batch, prefetch (FC)\n",
        "train_fc = dataset_fc.take(50000).batch(32).prefetch(1)\n",
        "validation_fc = dataset_fc.skip(50000).take(5000).batch(32).prefetch(1)\n",
        "test_fc = dataset_fc.skip(50000 + 5000).take(5000).batch(32).prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQwVOQiXnAen",
        "colab_type": "text"
      },
      "source": [
        "Definiamo ora **l'input per il modello conovluzionale**.\n",
        "\n",
        "Anche in questo caso, vogliamo effettuare la stessa trasformazione sulle label (codifica one-hot) e lo stesso scaling nel range [-1,1] per i valori di input dell'immagine.\n",
        "\n",
        "Possiamo quindi riutilizzare l'oggetto `dataset_fc`, cambiando semplicemente la forma da `(32*32*3)` all'originaria `(32,32,3`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgTHlGfdnkIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def undo_flattening(row):\n",
        "  row[\"image\"] = tf.reshape(row[\"image\"], (32,32,3))\n",
        "  return row\n",
        "\n",
        "# Input for the convolutional model\n",
        "dataset_cnn = dataset_fc.map(undo_flattening)\n",
        "\n",
        "# split, batch, prefetch (FC)\n",
        "train_cnn = dataset_cnn.take(50000).batch(32).prefetch(1)\n",
        "validation_cnn = dataset_cnn.skip(50000).take(5000).batch(32).prefetch(1)\n",
        "test_cnn = dataset_cnn.skip(50000 + 5000).take(5000).batch(32).prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR7tbx4orEWP",
        "colab_type": "text"
      },
      "source": [
        "## Definizione modelli\n",
        "\n",
        "Ri-utilizziamo il modello completamente connesso precedentemente definito, e definiamo un modello convoluzionale in grado di accettare immagini `32x32x3` in input.\n",
        "\n",
        "### Modello Completamente Connesso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwfqSUWjrV4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.keras.layers.Input(shape=(32*32*3))\n",
        "net = tf.keras.layers.Dense(512, activation=tf.nn.relu)(inputs)\n",
        "net = tf.keras.layers.Dense(256, activation=tf.nn.relu)(net)\n",
        "net = tf.keras.layers.Dense(128, activation=tf.nn.relu)(net)\n",
        "out = tf.keras.layers.Dense(10)(net)\n",
        "model_fc = tf.keras.Model(inputs=inputs, outputs=out)\n",
        "model_fc.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJvLPwFwrfoH",
        "colab_type": "text"
      },
      "source": [
        "## Definizione Rete Neurale Convoluzionale\n",
        "\n",
        "La struttura della rete, esattamente come per il caso FC, è arbitraria.\n",
        "\n",
        "Dato che il nostro obiettivo è quello di confrontare le performance (in termini di numero di parametri e metriche misurate) dei due modelli, cerchiamo di definire la CNN in modo \"simile\" alla rete FC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNr-nG-zrdc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Begin definition: feature extractor\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
        "net = tf.keras.layers.Conv2D(32, (5,5), strides=(2,2), padding='same', activation=tf.nn.relu)(inputs)\n",
        "# padding = same -> output side = input_side / stride = 16\n",
        "# output shape = (16,16,32)\n",
        "net = tf.keras.layers.Conv2D(64, (5,5), strides=(2,2), padding='same', activation=tf.nn.relu)(net)\n",
        "# output shape = (8,8,64)\n",
        "net = tf.keras.layers.Conv2D(128, (5,5), strides=(2,2), padding='same', activation=tf.nn.relu)(net)\n",
        "# output size = (4, 4, 128)\n",
        "\n",
        "# Classification layer: flatten the (4,4,128) tensor in a (4*4*128) tensor\n",
        "net = tf.keras.layers.Flatten()(net)\n",
        "# End definition: feature extractor\n",
        "\n",
        "# Classification layer\n",
        "out = tf.keras.layers.Dense(10)(net)\n",
        "\n",
        "# building the whole model\n",
        "model_cnn = tf.keras.Model(inputs=inputs, outputs=out)\n",
        "model_cnn.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytON8dzKt9pD",
        "colab_type": "text"
      },
      "source": [
        "### Differenze\n",
        "\n",
        "Il numero di parametri della rete FC è 1,738,890 mentre la CNN ha solo 279,114 parametri.\n",
        "\n",
        "La rete neurale convoluzionale ha un numero di parametri di \\~6 volte inferiore, il ché significa **\\~600%** di parametri in meno.\n",
        "\n",
        "Il numero di parametri della CNN aumenta all'aumentare della profondita, ma aumenta solo perché abbiamo arbitrariamente deciso di mettere più parametri apprendibili (numero di filtri) nei layer \"deep\" della rete.\n",
        "\n",
        "La rete completamente connessa, invece, ha un numero di parametri che diminuisce layer dopo layer (perché abbiamo definito l'archiettura in questo modo), ma **il solo layer di input** ha più parametri di tutta la CNN.\n",
        "\n",
        "## Definizione e riuso di oggetti Keras\n",
        "\n",
        "La CNN è in tutto e per tutto un classificatore, quindi possiamo riutilizzare la categorical cross-entropy loss.\n",
        "\n",
        "Possiamo quindi definire un oggetto callable (una Keras loss) e ritutilizzarla per il train di entrambi i modelli. Alla fine, la keras loss altro non fa che mettere in relazione l'output prodotto dalla rete e la predizione attesa; non avendo alcuno stato al suo interno possiamo utilizzarla senza alcun problema per il train di due modelli.\n",
        "\n",
        "Lo stesso ragionamento si può applicare anche all'ottimizzatore (solo finché utilizziamo SGD ed altri ottimizzatori senza variabili), deve solo applicare la regola di aggiornamento e non ha alcuno stato.\n",
        "\n",
        "È invece **sbagliato** riutilizzare la stessa `tf.GradientTape` dato che questa tiene traccia di quanto accade all'interno dello step di train ed il suo contenuto **viene distrutto** nel momento in cui viene invocato il metodo `.gradient`.\n",
        "\n",
        "Ed è **sbagliato** anche riutilizzare gli stessi oggetti `tf.keras.metric` in quanto anch'essi dotati di uno stato (e lo stato e relativo alle performance dello specifico modello)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNoyBLlKywkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss is a callable object\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Metrics\n",
        "accuracy_cnn = tf.keras.metrics.Accuracy()\n",
        "mean_loss_cnn = tf.keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "accuracy_fc = tf.keras.metrics.Accuracy()\n",
        "mean_loss_fc = tf.keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
        "\n",
        "def compute_loss(input_samples, model):\n",
        "    predictions = model(input_samples[\"image\"])\n",
        "    loss_value = loss(input_samples[\"label\"], predictions)\n",
        "    return loss_value\n",
        "\n",
        "@tf.function\n",
        "def train_step(input_samples, model):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = compute_loss(input_samples, model)\n",
        "\n",
        "  gradient = tape.gradient(loss_value, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
        "\n",
        "  return loss_value\n",
        "\n",
        "def measure_metrics(input_samples, model, id):\n",
        "  predicted_labels = tf.argmax(model(input_samples[\"image\"]), axis=1)\n",
        "  if id == \"cnn\":\n",
        "      accuracy_cnn.update_state(tf.argmax(input_samples[\"label\"], axis=1), predicted_labels)\n",
        "      mean_loss_cnn.update_state(compute_loss(input_samples, model))\n",
        "  else:\n",
        "    accuracy_fc.update_state(tf.argmax(input_samples[\"label\"], axis=1), predicted_labels)\n",
        "    mean_loss_fc.update_state(compute_loss(input_samples, model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXbX-Eqt9SlW",
        "colab_type": "text"
      },
      "source": [
        "## Logging\n",
        "\n",
        "Dato che vogliamo confrontare le performance del modello FC e del modello CNN, è necessario creare il corretto numero di `FileWriter' ed usarli correttamente.\n",
        "\n",
        "Dato che TensorBoard utilizza la struttura delle cartelle per creare curve differenti sullo stesso grafico, possiamo definire sei diversi writer nelle directory corrette:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJv09lAfyw60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FC writers\n",
        "train_writer_fc = tf.summary.create_file_writer(\"logs/train/fc\")\n",
        "validation_writer_fc = tf.summary.create_file_writer(\"logs/validation/fc\")\n",
        "test_writer_fc = tf.summary.create_file_writer(\"logs/test/fc\")\n",
        "\n",
        "# CNN writers\n",
        "train_writer_cnn = tf.summary.create_file_writer(\"logs/train/cnn\")\n",
        "validation_writer_cnn = tf.summary.create_file_writer(\"logs/validation/cnn\")\n",
        "test_writer_cnn = tf.summary.create_file_writer(\"logs/test/cnn\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoRAdh5yy-vd",
        "colab_type": "text"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Siamo ora pronti per definire il training loop.\n",
        "La funzione accetterà il modello, il dataset, e l'ID (\"cnn\" o \"fc\") corretto ed allenerà il modello per il numero desiderato di epoche.\n",
        "\n",
        "Dato che vogliamo fare due train distinti, ma plottarli sullo stesso grafico come se fossero stati eseguiti in parallelo, dobbiamo ricordarci di azzerare la variable `global_step` e `epoch_counter` al termine del primo training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOshd7y9zd0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_step = tf.Variable(0, dtype=tf.int64, trainable=False)\n",
        "epoch_counter = tf.Variable(0, dtype=tf.int64, trainable=False)\n",
        "\n",
        "def train_loop(num_epochs, model, dataset, id):\n",
        "  if id == \"cnn\":\n",
        "    mean_loss = mean_loss_cnn\n",
        "    accuracy = accuracy_cnn\n",
        "    train_writer = train_writer_cnn\n",
        "  else:\n",
        "    mean_loss = mean_loss_fc\n",
        "    accuracy = accuracy_fc\n",
        "    train_writer = train_writer_fc\n",
        "\n",
        "  # Loop\n",
        "  for epoch in tf.range(epoch_counter, num_epochs):\n",
        "    for input_samples in dataset:\n",
        "      loss_value = train_step(input_samples, model)\n",
        "      measure_metrics(input_samples, model, id)\n",
        "      global_step.assign_add(1)\n",
        "\n",
        "      if tf.equal(tf.math.mod(global_step, 100), 0):\n",
        "        mean_loss_value = mean_loss.result() \n",
        "        accuracy_value = accuracy.result()\n",
        "        mean_loss.reset_states()\n",
        "        accuracy.reset_states()\n",
        "        tf.print(f\"[{global_step.numpy()}] loss value: \", mean_loss_value,\" - train acc: \", accuracy_value)\n",
        "        with train_writer.as_default():\n",
        "          tf.summary.scalar(\"loss\", mean_loss_value, step=global_step)\n",
        "          tf.summary.scalar(\"accuracy\", accuracy_value, step=global_step)\n",
        "          tf.summary.image(\"images\", tf.reshape(input_samples[\"image\"], (-1, 32,32,3)), step=global_step, max_outputs=5)\n",
        "    # end of epoch: measure performance on validation set and log the values on tensorboard\n",
        "    tf.print(f\"Epoch {epoch.numpy() + 1 } completed\")\n",
        "    epoch_counter.assign(epoch + 1)\n",
        "    # TODO: insert validation code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWIPMJKz0gxv",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard e training\n",
        "\n",
        "Lanciamo tensorboard e subito dopo invochiamo la funzione di train: prima sul modello fc, poi resettiamo le due variabili globali, e infine alleniamo il modello cnn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1ORzblO0roT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-nDstZz0u_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_step.assign(0)\n",
        "epoch_counter.assign(0)\n",
        "train_loop(num_epochs=5, model=model_fc, dataset=train_fc, id=\"fc\")\n",
        "\n",
        "print(\"#### END FC MODEL TRAINING ####\")\n",
        "global_step.assign(0)\n",
        "epoch_counter.assign(0)\n",
        "train_loop(num_epochs=5, model=model_cnn, dataset=train_cnn, id=\"cnn\")\n",
        "print(\"#### END CNN MODEL TRAINING ####\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-fcRha90yvm",
        "colab_type": "text"
      },
      "source": [
        "## Considerazioni\n",
        "\n",
        "Abbiamo ottenuto delle perforamance (misurate solo sul training set) comparabili tra i due modelli, ma il modello convouzionale ha un numero di parametri molto minore, il ché implica una maggiore velocità di training e di inferenza.\n",
        "\n",
        "Inoltre, essendo un modello con pochi parametri per layer, è possibile aggiungere ulteriri layer all'architettura per renderla più deep, aumentando (con molta probabilità) la qualità del classificatore."
      ]
    }
  ]
}